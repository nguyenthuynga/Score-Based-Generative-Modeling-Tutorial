{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remeber to run \" export CUDA_VISIBLE_DEVICES=3 \" and then \" jupyter notebook \" on the terminal after activating env diffusion\n",
    "import os\n",
    "gpu=\"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu #change 4: add this line in every cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JnbivYqLDLI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "YyQtV7155Nht"
   },
   "outputs": [],
   "source": [
    "#@title Defining a time-dependent score-based model (double click to expand or collapse)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed\n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "\n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    # Obtain the Gaussian random feature embedding for t\n",
    "    embed = self.act(self.embed(t))\n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)\n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv4(h4)\n",
    "    ## Skip connection from the encoding path\n",
    "    h += self.dense5(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense6(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LZC7wrOvxLdL"
   },
   "outputs": [],
   "source": [
    "#@title Set up the SDE\n",
    "import functools  # Import the functools module\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"\n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "\n",
    "sigma =  25.0#@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zOsoqPdXHuL5"
   },
   "outputs": [],
   "source": [
    "#@title Define the loss function (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, random_t)\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "d9137abb137244719edd3ebf68a00ef5",
      "ef5a45bda6934583b9ad35f7cfa15de3",
      "75c1ed28ea244f478e534167ba320bf8",
      "2576dac8e2f543b0a079ebcb7fdb8cde",
      "a994b959ae954906b38754bf9341f7d6",
      "7aad71767f104a17baab1914ff83962b",
      "040615b2be0f47459f08bf0fae024ce2",
      "4dfc7d0791b443b0812dae8cff2bd4fa",
      "6fb58ebffb0241afb0bee2bf8766a3ea",
      "af2029c690eb4b008dee1efbf7c6c88e",
      "30febdb809564f80bcfe844ef45cc178"
     ]
    },
    "executionInfo": {
     "elapsed": 26412,
     "status": "ok",
     "timestamp": 1723554971378,
     "user": {
      "displayName": "Thi Thuy Nga Nguyen",
      "userId": "04140656316676043006"
     },
     "user_tz": -120
    },
    "id": "8PPsLx4dGCGa",
    "outputId": "c61a4bd5-27d5-47a1-df4d-9afa9da2de23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2168818/3315192203.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "Average Loss: 301.735652: 100%|██████████| 1/1 [00:18<00:00, 18.27s/it]\n"
     ]
    }
   ],
   "source": [
    "#@title Training (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "import torch\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "#from tqdm.notebook import trange\n",
    "from tqdm import trange ##change 1: because tqdm.notebook import trange doesn't work \n",
    "\n",
    "\n",
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "n_epochs =   1#@param {'type':'integer'}#change 2: i changed 50 to 1 so that it run faster\n",
    "## size of a mini-batch\n",
    "batch_size =  32 #@param {'type':'integer'}#change 3: reduce batchsize from 32 to 8\n",
    "## learning rate\n",
    "lr=1e-4 #@param {'type':'number'}\n",
    "\n",
    "dataset = MNIST('.', train=True, transform=transforms.ToTensor(), download=True)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "tqdm_epoch = trange(n_epochs)\n",
    "for epoch in tqdm_epoch:\n",
    "  print(\"epoch: \", epoch)\n",
    "  avg_loss = 0.\n",
    "  num_items = 0\n",
    "  for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    loss = loss_fn(score_model, x, marginal_prob_std_fn)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    avg_loss += loss.item() * x.shape[0]\n",
    "    num_items += x.shape[0]\n",
    "  # Print the averaged training loss so far.\n",
    "  tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "  # Update the checkpoint after each epoch of training.\n",
    "  torch.save(score_model.state_dict(), 'ckpt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tldaUHUtHuej"
   },
   "source": [
    "## Sampling with Numerical SDE Solvers\n",
    "Recall that for any SDE of the form\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) dt + g(t) d\\mathbf{w},\n",
    "\\end{align*}\n",
    "the reverse-time SDE is given by\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = [\\mathbf{f}(\\mathbf{x}, t) - g(t)^2 \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})] dt + g(t) d \\bar{\\mathbf{w}}.\n",
    "\\end{align*}\n",
    "Since we have chosen the forward SDE to be\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\sigma^t d\\mathbf{w}, \\quad t\\in[0,1]\n",
    "\\end{align*}\n",
    "The reverse-time SDE is given by\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} = -\\sigma^{2t} \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x}) dt + \\sigma^t d \\bar{\\mathbf{w}}.\n",
    "\\end{align*}\n",
    "To sample from our time-dependent score-based model $s_\\theta(\\mathbf{x}, t)$, we first draw a sample from the prior distribution $p_1 \\approx \\mathbf{N}\\bigg(\\mathbf{x}; \\mathbf{0}, \\frac{1}{2}(\\sigma^{2} - 1) \\mathbf{I}\\bigg)$, and then solve the reverse-time SDE with numerical methods.\n",
    "\n",
    "In particular, using our time-dependent score-based model, the reverse-time SDE can be approximated by\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} = -\\sigma^{2t} s_\\theta(\\mathbf{x}, t) dt + \\sigma^t d \\bar{\\mathbf{w}}\n",
    "\\end{align*}\n",
    "\n",
    "Next, one can use numerical methods to solve for the reverse-time SDE, such as the [Euler-Maruyama](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method) approach. It is based on a simple discretization to the SDE, replacing $dt$ with $\\Delta t$ and $d \\mathbf{w}$ with $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, g^2(t) \\Delta t \\mathbf{I})$. When applied to our reverse-time SDE, we can obtain the following iteration rule\n",
    "\\begin{align}\n",
    "\\mathbf{x}_{t-\\Delta t} = \\mathbf{x}_t + \\sigma^{2t} s_\\theta(\\mathbf{x}_t, t)\\Delta t + \\sigma^t\\sqrt{\\Delta t} \\mathbf{z}_t,\n",
    "\\end{align}\n",
    "where $\\mathbf{z}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6FxBTOSSH2QR"
   },
   "outputs": [],
   "source": [
    "#@title Define the Euler-Maruyama sampler (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff,\n",
    "                           batch_size=64,\n",
    "                           num_steps=num_steps,\n",
    "                           device='cuda',\n",
    "                           eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    Samples.\n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn(batch_size, 1, 28, 28, device=device) \\\n",
    "    * marginal_prob_std(t)[:, None, None, None]\n",
    "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm.notebook.tqdm(time_steps):\n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      mean_x = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step) * step_size\n",
    "      x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "  # Do not include any noise in the last sampling step.\n",
    "  return mean_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC6QVkUQvFyB"
   },
   "source": [
    "## Sampling with Predictor-Corrector Methods\n",
    "\n",
    "Aside from generic numerical SDE solvers, we can leverage special properties of our reverse-time SDE for better solutions. Since we have an estimate of the score of $p_t(\\mathbf{x}(t))$ via the score-based model, i.e., $s_\\theta(\\mathbf{x}, t) \\approx \\nabla_{\\mathbf{x}(t)} \\log p_t(\\mathbf{x}(t))$, we can leverage score-based MCMC approaches, such as Langevin MCMC, to correct the solution obtained by numerical SDE solvers.\n",
    "\n",
    "Score-based MCMC approaches can produce samples from a distribution $p(\\mathbf{x})$ once its score $\\nabla_\\mathbf{x} \\log p(\\mathbf{x})$ is known. For example, Langevin MCMC operates by running the following iteration rule for $i=1,2,\\cdots, N$:\n",
    "\\begin{align*}\n",
    "\\mathbf{x}_{i+1} = \\mathbf{x}_{i} + \\epsilon \\nabla_\\mathbf{x} \\log p(\\mathbf{x}_i) + \\sqrt{2\\epsilon} \\mathbf{z}_i,\n",
    "\\end{align*}\n",
    "where $\\mathbf{z}_i \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, $\\epsilon > 0$ is the step size, and $\\mathbf{x}_1$ is initialized from any prior distribution $\\pi(\\mathbf{x}_1)$. When $N\\to\\infty$ and $\\epsilon \\to 0$, the final value $\\mathbf{x}_{N+1}$ becomes a sample from $p(\\mathbf{x})$ under some regularity conditions. Therefore, given $s_\\theta(\\mathbf{x}, t) \\approx \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})$, we can get an approximate sample from $p_t(\\mathbf{x})$ by running several steps of Langevin MCMC, replacing $\\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})$ with $s_\\theta(\\mathbf{x}, t)$ in the iteration rule.\n",
    "\n",
    "Predictor-Corrector samplers combine both numerical solvers for the reverse-time SDE and the Langevin MCMC approach. In particular, we first apply one step of numerical SDE solver to obtain $\\mathbf{x}_{t-\\Delta t}$ from $\\mathbf{x}_t$, which is called the \"predictor\" step. Next, we apply several steps of Langevin MCMC to refine $\\mathbf{x}_t$, such that $\\mathbf{x}_t$ becomes a more accurate sample from $p_{t-\\Delta t}(\\mathbf{x})$. This is the \"corrector\" step as the MCMC helps reduce the error of the numerical SDE solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qW1HaPZb9gDM"
   },
   "outputs": [],
   "source": [
    "#@title Define the Predictor-Corrector sampler (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "signal_to_noise_ratio = 0.16 #@param {'type':'number'}\n",
    "\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def pc_sampler(score_model,\n",
    "               marginal_prob_std,\n",
    "               diffusion_coeff,\n",
    "               batch_size=64,\n",
    "               num_steps=num_steps,\n",
    "               snr=signal_to_noise_ratio,\n",
    "               device='cuda',\n",
    "               eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with Predictor-Corrector method.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient\n",
    "      of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    Samples.\n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn(batch_size, 1, 28, 28, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "  time_steps = np.linspace(1., eps, num_steps)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm.notebook.tqdm(time_steps):\n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      # Corrector step (Langevin MCMC)\n",
    "      grad = score_model(x, batch_time_step)\n",
    "      grad_norm = torch.norm(grad.reshape(grad.shape[0], -1), dim=-1).mean()\n",
    "      noise_norm = np.sqrt(np.prod(x.shape[1:]))\n",
    "      langevin_step_size = 2 * (snr * noise_norm / grad_norm)**2\n",
    "      x = x + langevin_step_size * grad + torch.sqrt(2 * langevin_step_size) * torch.randn_like(x)\n",
    "\n",
    "      # Predictor step (Euler-Maruyama)\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      x_mean = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step) * step_size\n",
    "      x = x_mean + torch.sqrt(g**2 * step_size)[:, None, None, None] * torch.randn_like(x)\n",
    "\n",
    "    # The last step does not include any noise\n",
    "    return x_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PdMMadpUbrj"
   },
   "source": [
    "## Sampling with Numerical ODE Solvers\n",
    "\n",
    "For any SDE of the form\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) d t + g(t) d \\mathbf{w},\n",
    "\\end{align*}\n",
    "there exists an associated ordinary differential equation (ODE)\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\bigg[\\mathbf{f}(\\mathbf{x}, t) - \\frac{1}{2}g(t)^2 \\nabla_\\mathbf{x} \\log p_t(\\mathbf{x})\\bigg] dt,\n",
    "\\end{align*}\n",
    "such that their trajectories have the same mariginal probability density $p_t(\\mathbf{x})$. Therefore, by solving this ODE in the reverse time direction, we can sample from the same distribution as solving the reverse-time SDE.\n",
    "We call this ODE the *probability flow ODE*.\n",
    "\n",
    "Below is a schematic figure showing how trajectories from this probability flow ODE differ from SDE trajectories, while still sampling from the same distribution.\n",
    "![SDE and ODE](https://drive.google.com/uc?id=1CGFbtY2mCjlIY8pjvoGevfa_32d4b1dj)\n",
    "\n",
    "Therefore, we can start from a sample from $p_T$, integrate the ODE in the reverse time direction, and then get a sample from $p_0$. In particular, for the SDE in our running example, we can integrate the following ODE from $t=T$ to $0$ for sample generation\n",
    "\\begin{align*}\n",
    "d\\mathbf{x} =  -\\frac{1}{2}\\sigma^{2t} s_\\theta(\\mathbf{x}, t) dt.\n",
    "\\end{align*}\n",
    "This can be done using many black-box ODE solvers provided by packages such as `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nxrCTFM8CfDN"
   },
   "outputs": [],
   "source": [
    "#@title Define the ODE sampler (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "from scipy import integrate\n",
    "\n",
    "## The error tolerance for the black-box ODE solver\n",
    "error_tolerance = 1e-5 #@param {'type': 'number'}\n",
    "def ode_sampler(score_model,\n",
    "                marginal_prob_std,\n",
    "                diffusion_coeff,\n",
    "                batch_size=64,\n",
    "                atol=error_tolerance,\n",
    "                rtol=error_tolerance,\n",
    "                device='cuda',\n",
    "                z=None,\n",
    "                eps=1e-3):\n",
    "  \"\"\"Generate samples from score-based models with black-box ODE solvers.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that returns the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    atol: Tolerance of absolute errors.\n",
    "    rtol: Tolerance of relative errors.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    z: The latent code that governs the final sample. If None, we start from p_1;\n",
    "      otherwise, we start from the given z.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  # Create the latent code\n",
    "  if z is None:\n",
    "    init_x = torch.randn(batch_size, 1, 28, 28, device=device) \\\n",
    "      * marginal_prob_std(t)[:, None, None, None]\n",
    "  else:\n",
    "    init_x = z\n",
    "\n",
    "  shape = init_x.shape\n",
    "\n",
    "  def score_eval_wrapper(sample, time_steps):\n",
    "    \"\"\"A wrapper of the score-based model for use by the ODE solver.\"\"\"\n",
    "    sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
    "    time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))\n",
    "    with torch.no_grad():\n",
    "      score = score_model(sample, time_steps)\n",
    "    return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
    "\n",
    "  def ode_func(t, x):\n",
    "    \"\"\"The ODE function for use by the ODE solver.\"\"\"\n",
    "    time_steps = np.ones((shape[0],)) * t\n",
    "    g = diffusion_coeff(torch.tensor(t)).cpu().numpy()\n",
    "    return  -0.5 * (g**2) * score_eval_wrapper(x, time_steps)\n",
    "\n",
    "  # Run the black-box ODE solver.\n",
    "  res = integrate.solve_ivp(ode_func, (1., eps), init_x.reshape(-1).cpu().numpy(), rtol=rtol, atol=atol, method='RK45')\n",
    "  print(f\"Number of function evaluations: {res.nfev}\")\n",
    "  x = torch.tensor(res.y[:, -1], device=device).reshape(shape)\n",
    "\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "executionInfo": {
     "elapsed": 5706,
     "status": "ok",
     "timestamp": 1723555092356,
     "user": {
      "displayName": "Thi Thuy Nga Nguyen",
      "userId": "04140656316676043006"
     },
     "user_tz": -120
    },
    "id": "kKoAPnr7Pf2B",
    "outputId": "0800390d-1daf-474f-a5fe-949f585df3cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2168818/3315192203.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "/tmp/ipykernel_2168818/3315192203.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sigma**t, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of function evaluations: 560\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Sampling (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "## Load the pre-trained checkpoint from disk.\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "ckpt = torch.load('ckpt.pth', map_location=device)\n",
    "score_model.load_state_dict(ckpt)\n",
    "\n",
    "sample_batch_size = 2 #@param {'type':'integer'} #change 10: I use 2 instead of 64 to make it faster\n",
    "sampler = ode_sampler #@param ['Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'] {'type': 'raw'}\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "                  marginal_prob_std_fn,\n",
    "                  diffusion_coeff_fn,\n",
    "                  sample_batch_size,\n",
    "                  device=device)\n",
    "\n",
    "## Sample visualization.\n",
    "samples = samples.clamp(0.0, 1.0)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC49nk6ZXqOS"
   },
   "source": [
    "## Likelihood Computation\n",
    "\n",
    "A by-product of the probability flow ODE formulation is likelihood computation. Suppose we have a differentiable one-to-one mapping $\\mathbf{h}$ that transforms a data sample $\\mathbf{x} \\sim p_0$ to a prior distribution $\\mathbf{h}(\\mathbf{x}) \\sim p_T$. We can compute the likelihood of $p_0(\\mathbf{x})$ via the following [change-of-variable formula](https://en.wikipedia.org/wiki/Probability_density_function#Function_of_random_variables_and_change_of_variables_in_the_probability_density_function)\n",
    "\\begin{align*}\n",
    "p_0(\\mathbf{x}) = p_T(\\mathbf{h}(\\mathbf{x})) |\\operatorname{det}(J_\\mathbf{h}(\\mathbf{x}))|,\n",
    "\\end{align*}\n",
    "where $J_\\mathbf{h}(\\mathbf{x})$ represents the Jacobian of the mapping $\\mathbf{h}$, and we assume it is efficient to evaluate the likelihood of the prior distribution $p_T$.\n",
    "\n",
    "The trajectories of an ODE also define a one-to-one mapping from $\\mathbf{x}(0)$ to $\\mathbf{x}(T)$. For ODEs of the form\n",
    "\\begin{align*}\n",
    "d \\mathbf{x} = \\mathbf{f}(\\mathbf{x}, t) dt,\n",
    "\\end{align*}\n",
    "there exists an [instantaneous change-of-variable formula](https://arxiv.org/abs/1806.07366) that connects the probability of $p_0(\\mathbf{x})$ and $p_1(\\mathbf{x})$, given by\n",
    "\\begin{align*}\n",
    "p_0 (\\mathbf{x}(0)) = e^{\\int_0^1 \\operatorname{div} \\mathbf{f}(\\mathbf{x}(t), t) d t} p_1(\\mathbf{x}(1)),\n",
    "\\end{align*}\n",
    "where $\\operatorname{div}$ denotes the divergence function (trace of Jacobian).\n",
    "\n",
    "In practice, this divergence function can be hard to evaluate for general vector-valued function $\\mathbf{f}$, but we can use an unbiased estimator, named [Skilling-Hutchinson estimator](http://blog.shakirm.com/2015/09/machine-learning-trick-of-the-day-3-hutchinsons-trick/), to approximate the trace. Let $\\boldsymbol \\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. The Skilling-Hutchinson estimator is based on the fact that\n",
    "\\begin{align*}\n",
    "\\operatorname{div} \\mathbf{f}(\\mathbf{x}) = \\mathbb{E}_{\\boldsymbol\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})}[\\boldsymbol\\epsilon^\\intercal  J_\\mathbf{f}(\\mathbf{x}) \\boldsymbol\\epsilon].\n",
    "\\end{align*}\n",
    "Therefore, we can simply sample a random vector $\\boldsymbol \\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, and then use $\\boldsymbol \\epsilon^\\intercal J_\\mathbf{f}(\\mathbf{x}) \\boldsymbol \\epsilon$ to estimate the divergence of $\\mathbf{f}(\\mathbf{x})$. This estimator only requires computing the Jacobian-vector product $J_\\mathbf{f}(\\mathbf{x})\\boldsymbol \\epsilon$, which is typically efficient.\n",
    "\n",
    "As a result, for our probability flow ODE, we can compute the (log) data likelihood with the following\n",
    "\\begin{align*}\n",
    "\\log p_0(\\mathbf{x}(0)) = \\log p_1(\\mathbf{x}(1)) -\\frac{1}{2}\\int_0^1 \\frac{d[\\sigma^2(t)]}{dt} \\operatorname{div} s_\\theta(\\mathbf{x}(t), t) dt.\n",
    "\\end{align*}\n",
    "With the Skilling-Hutchinson estimator, we can compute the divergence via\n",
    "\\begin{align*}\n",
    "\\operatorname{div} s_\\theta(\\mathbf{x}(t), t) = \\mathbb{E}_{\\boldsymbol\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})}[\\boldsymbol\\epsilon^\\intercal  J_{s_\\theta}(\\mathbf{x}(t), t) \\boldsymbol\\epsilon].\n",
    "\\end{align*}\n",
    "Afterwards, we can compute the integral with numerical integrators. This gives us an unbiased estimate to the true data likelihood, and we can make it more and more accurate when we run it multiple times and take the average. The numerical integrator requires $\\mathbf{x}(t)$ as a function of $t$, which can be obtained by the probability flow ODE sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DfOkg5jBZcjF"
   },
   "outputs": [],
   "source": [
    "#@title Define the likelihood function (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "def prior_likelihood(z, sigma):\n",
    "  \"\"\"The likelihood of a Gaussian distribution with mean zero and\n",
    "      standard deviation sigma.\"\"\"\n",
    "  shape = z.shape\n",
    "  N = np.prod(shape[1:])\n",
    "  return -N / 2. * torch.log(2*np.pi*sigma**2) - torch.sum(z**2, dim=(1,2,3)) / (2 * sigma**2)\n",
    "\n",
    "def ode_likelihood(x,\n",
    "                   score_model,\n",
    "                   marginal_prob_std,\n",
    "                   diffusion_coeff,\n",
    "                   batch_size=64,\n",
    "                   device='cuda',\n",
    "                   eps=1e-5):\n",
    "  \"\"\"Compute the likelihood with probability flow ODE.\n",
    "\n",
    "  Args:\n",
    "    x: Input data.\n",
    "    score_model: A PyTorch model representing the score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of the\n",
    "      perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the\n",
    "      forward SDE.\n",
    "    batch_size: The batch size. Equals to the leading dimension of `x`.\n",
    "    device: 'cuda' for evaluation on GPUs, and 'cpu' for evaluation on CPUs.\n",
    "    eps: A `float` number. The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    z: The latent code for `x`.\n",
    "    bpd: The log-likelihoods in bits/dim.\n",
    "  \"\"\"\n",
    "\n",
    "  # Draw the random Gaussian sample for Skilling-Hutchinson's estimator.\n",
    "  epsilon = torch.randn_like(x)\n",
    "\n",
    "  def divergence_eval(sample, time_steps, epsilon):\n",
    "    \"\"\"Compute the divergence of the score-based model with Skilling-Hutchinson.\"\"\"\n",
    "    with torch.enable_grad():\n",
    "      sample.requires_grad_(True)\n",
    "      score_e = torch.sum(score_model(sample, time_steps) * epsilon)\n",
    "      grad_score_e = torch.autograd.grad(score_e, sample)[0]\n",
    "    return torch.sum(grad_score_e * epsilon, dim=(1, 2, 3))\n",
    "\n",
    "  shape = x.shape\n",
    "\n",
    "  def score_eval_wrapper(sample, time_steps):\n",
    "    \"\"\"A wrapper for evaluating the score-based model for the black-box ODE solver.\"\"\"\n",
    "    sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
    "    time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))\n",
    "    with torch.no_grad():\n",
    "      score = score_model(sample, time_steps)\n",
    "    return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
    "\n",
    "  def divergence_eval_wrapper(sample, time_steps):\n",
    "    \"\"\"A wrapper for evaluating the divergence of score for the black-box ODE solver.\"\"\"\n",
    "    with torch.no_grad():\n",
    "      # Obtain x(t) by solving the probability flow ODE.\n",
    "      sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
    "      time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))\n",
    "      # Compute likelihood.\n",
    "      div = divergence_eval(sample, time_steps, epsilon)\n",
    "      return div.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
    "\n",
    "  def ode_func(t, x):\n",
    "    \"\"\"The ODE function for the black-box solver.\"\"\"\n",
    "    time_steps = np.ones((shape[0],)) * t\n",
    "    sample = x[:-shape[0]]\n",
    "    logp = x[-shape[0]:]\n",
    "    g = diffusion_coeff(torch.tensor(t)).cpu().numpy()\n",
    "    sample_grad = -0.5 * g**2 * score_eval_wrapper(sample, time_steps)\n",
    "    logp_grad = -0.5 * g**2 * divergence_eval_wrapper(sample, time_steps)\n",
    "    return np.concatenate([sample_grad, logp_grad], axis=0)\n",
    "\n",
    "  init = np.concatenate([x.cpu().numpy().reshape((-1,)), np.zeros((shape[0],))], axis=0)\n",
    "  # Black-box ODE solver\n",
    "  res = integrate.solve_ivp(ode_func, (eps, 1.), init, rtol=1e-5, atol=1e-5, method='RK45')\n",
    "  zp = torch.tensor(res.y[:, -1], device=device)\n",
    "  z = zp[:-shape[0]].reshape(shape)\n",
    "  delta_logp = zp[-shape[0]:].reshape(shape[0])\n",
    "  sigma_max = marginal_prob_std(1.)\n",
    "  prior_logp = prior_likelihood(z, sigma_max)\n",
    "  bpd = -(prior_logp + delta_logp) / np.log(2)\n",
    "  N = np.prod(shape[1:])\n",
    "  bpd = bpd / N + 8.\n",
    "  return z, bpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179,
     "referenced_widgets": [
      "b0bb145c0a794dd4aa17bf08b9925f40",
      "335ae0fe222b4b2184aef7407c3f569c",
      "a7afe390ae6c40acadeed98b3c3604ce",
      "3de665ea456147d98dc44b3ab559928a",
      "d60cf8b7bff94e8182ea7e61d6156c7b",
      "4087150b545049ffbf3e8dcab4fab62d",
      "56868c427fb8464a991eb973838d3857",
      "e34ec57bc6e1477f91365a6b9854e712",
      "830c569e91a145719e89e0a0a9ef3b3a",
      "ee7cd6116ebe4a36b6b7f42e6136752c",
      "9c7853a2c12647259111236f59210e21"
     ]
    },
    "id": "0H1Rq5DTmW8o",
    "outputId": "be3e2c3e-764c-4cc3-99d8-2898a9019c27"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2820443d62443ce947922dea8aaae88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1241698/3315192203.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sigma**t, device=device)\n",
      "/tmp/ipykernel_1241698/3315192203.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n"
     ]
    }
   ],
   "source": [
    "#@title Compute likelihood on the dataset (double click to expand or collapse)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "from tqdm.notebook import tqdm#i add this line, and the line tqdm.notebook.tqdm(data_loader) by tqdm(data_loader)\n",
    "# import tqdm\n",
    "batch_size = 32 #@param {'type':'integer'}\n",
    "\n",
    "dataset = MNIST('.', train=False, transform=transforms.ToTensor(), download=True)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "ckpt = torch.load('ckpt.pth', map_location=device)\n",
    "score_model.load_state_dict(ckpt)\n",
    "\n",
    "all_bpds = 0.\n",
    "all_items = 0\n",
    "try:\n",
    "  tqdm_data = tqdm(data_loader)\n",
    "  for x, _ in tqdm_data:\n",
    "    x = x.to(device)\n",
    "    # uniform dequantization\n",
    "    x = (x * 255. + torch.rand_like(x)) / 256.\n",
    "    _, bpd = ode_likelihood(x, score_model, marginal_prob_std_fn,\n",
    "                            diffusion_coeff_fn,\n",
    "                            x.shape[0], device=device, eps=1e-5)\n",
    "    all_bpds += bpd.sum()\n",
    "    all_items += bpd.shape[0]\n",
    "    tqdm_data.set_description(\"Average bits/dim: {:5f}\".format(all_bpds / all_items))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "  # Remove the error message when interuptted by keyboard or GUI.\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHsx75Yft-6u"
   },
   "source": [
    "## Further Resources\n",
    "\n",
    "If you're interested in learning more about score-based generative models, the following papers would be a good start:\n",
    "\n",
    "* Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. \"[Score-Based Generative Modeling through Stochastic Differential Equations.](https://arxiv.org/pdf/2011.13456.pdf)\" International Conference on Learning Representations, 2021.\n",
    "* Jonathan Ho, Ajay Jain, and Pieter Abbeel. \"[Denoising diffusion probabilistic models.](https://arxiv.org/pdf/2006.11239.pdf)\" Advances in Neural Information Processing Systems. 2020.\n",
    "*    Yang Song, and Stefano Ermon. \"[Improved Techniques for Training Score-Based Generative Models.](https://arxiv.org/pdf/2006.09011.pdf)\" Advances in Neural Information Processing Systems. 2020.\n",
    "*   Yang Song, and Stefano Ermon. \"[Generative modeling by estimating gradients of the data distribution.](https://arxiv.org/pdf/1907.05600.pdf)\" Advances in Neural Information Processing Systems. 2019.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1CzbeDmhkJ05ro5l1H3rGSgN7L3xbo6fg",
     "timestamp": 1723555169369
    },
    {
     "file_id": "120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3",
     "timestamp": 1723106048284
    },
    {
     "file_id": "1YbT61SuuIc2mcYWH7KA_Gv49EN3M8VE4",
     "timestamp": 1611090576605
    },
    {
     "file_id": "1gJGl7J18aP9jR5_2gjwQOcn8RWZegUR6",
     "timestamp": 1603207633254
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "040615b2be0f47459f08bf0fae024ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2576dac8e2f543b0a079ebcb7fdb8cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af2029c690eb4b008dee1efbf7c6c88e",
      "placeholder": "​",
      "style": "IPY_MODEL_30febdb809564f80bcfe844ef45cc178",
      "value": " 1/1 [00:26&lt;00:00, 26.03s/it]"
     }
    },
    "30febdb809564f80bcfe844ef45cc178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "335ae0fe222b4b2184aef7407c3f569c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4087150b545049ffbf3e8dcab4fab62d",
      "placeholder": "​",
      "style": "IPY_MODEL_56868c427fb8464a991eb973838d3857",
      "value": "Average bits/dim: 6.978904:   2%"
     }
    },
    "3de665ea456147d98dc44b3ab559928a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee7cd6116ebe4a36b6b7f42e6136752c",
      "placeholder": "​",
      "style": "IPY_MODEL_9c7853a2c12647259111236f59210e21",
      "value": " 7/313 [00:58&lt;42:35,  8.35s/it]"
     }
    },
    "4087150b545049ffbf3e8dcab4fab62d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dfc7d0791b443b0812dae8cff2bd4fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56868c427fb8464a991eb973838d3857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fb58ebffb0241afb0bee2bf8766a3ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75c1ed28ea244f478e534167ba320bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dfc7d0791b443b0812dae8cff2bd4fa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fb58ebffb0241afb0bee2bf8766a3ea",
      "value": 1
     }
    },
    "7aad71767f104a17baab1914ff83962b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "830c569e91a145719e89e0a0a9ef3b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9c7853a2c12647259111236f59210e21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7afe390ae6c40acadeed98b3c3604ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e34ec57bc6e1477f91365a6b9854e712",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_830c569e91a145719e89e0a0a9ef3b3a",
      "value": 7
     }
    },
    "a994b959ae954906b38754bf9341f7d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af2029c690eb4b008dee1efbf7c6c88e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0bb145c0a794dd4aa17bf08b9925f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_335ae0fe222b4b2184aef7407c3f569c",
       "IPY_MODEL_a7afe390ae6c40acadeed98b3c3604ce",
       "IPY_MODEL_3de665ea456147d98dc44b3ab559928a"
      ],
      "layout": "IPY_MODEL_d60cf8b7bff94e8182ea7e61d6156c7b"
     }
    },
    "d60cf8b7bff94e8182ea7e61d6156c7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9137abb137244719edd3ebf68a00ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef5a45bda6934583b9ad35f7cfa15de3",
       "IPY_MODEL_75c1ed28ea244f478e534167ba320bf8",
       "IPY_MODEL_2576dac8e2f543b0a079ebcb7fdb8cde"
      ],
      "layout": "IPY_MODEL_a994b959ae954906b38754bf9341f7d6"
     }
    },
    "e34ec57bc6e1477f91365a6b9854e712": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee7cd6116ebe4a36b6b7f42e6136752c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef5a45bda6934583b9ad35f7cfa15de3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7aad71767f104a17baab1914ff83962b",
      "placeholder": "​",
      "style": "IPY_MODEL_040615b2be0f47459f08bf0fae024ce2",
      "value": "Average Loss: 273.385721: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
